{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization to prominent sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: odfpy in c:\\users\\monique\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\monique\\anaconda3\\lib\\site-packages (from odfpy) (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\monique\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Gender_label</th>\n",
       "      <th>Gender_binary</th>\n",
       "      <th>User_name</th>\n",
       "      <th>Succession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>American entrepreneur, media proprietor, inves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>South African entrepreneur and business magnat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>BillGates</td>\n",
       "      <td>American business magnate, software developer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>tim_cook</td>\n",
       "      <td>American business executive who has been the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Flannery</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>JohnFlannery_GE</td>\n",
       "      <td>American business executive. He succeeded Jeff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Priti Patel</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>pritipatel</td>\n",
       "      <td>British politician who has been serving as Hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Liz Truss</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>trussliz</td>\n",
       "      <td>British politician serving as Foreign Secretar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Suella Braverman</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>SuellaBraverman</td>\n",
       "      <td>British politician. She was appointed Attorney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Ann Curry</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>AnnCurry</td>\n",
       "      <td>American journalist and photojournalist, Co-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Greta Van Susteren</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>greta</td>\n",
       "      <td>American commentator, lawyer, and former telev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Author Gender_label  Gender_binary        User_name  \\\n",
       "0            Jeff Bezos         male              0        JeffBezos   \n",
       "1             Elon Musk         male              0         elonmusk   \n",
       "2            Bill Gates         male              0        BillGates   \n",
       "3              Tim Cook         male              0         tim_cook   \n",
       "4         John Flannery         male              0  JohnFlannery_GE   \n",
       "..                  ...          ...            ...              ...   \n",
       "235        Priti Patel        female              1       pritipatel   \n",
       "236           Liz Truss       female              1         trussliz   \n",
       "237    Suella Braverman       female              1  SuellaBraverman   \n",
       "238          Ann Curry        female              1         AnnCurry   \n",
       "239  Greta Van Susteren       female              1           greta    \n",
       "\n",
       "                                            Succession  \n",
       "0    American entrepreneur, media proprietor, inves...  \n",
       "1    South African entrepreneur and business magnat...  \n",
       "2    American business magnate, software developer,...  \n",
       "3    American business executive who has been the c...  \n",
       "4    American business executive. He succeeded Jeff...  \n",
       "..                                                 ...  \n",
       "235  British politician who has been serving as Hom...  \n",
       "236  British politician serving as Foreign Secretar...  \n",
       "237  British politician. She was appointed Attorney...  \n",
       "238  American journalist and photojournalist, Co-an...  \n",
       "239  American commentator, lawyer, and former telev...  \n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install odfpy\n",
    "import pandas as pd\n",
    "\n",
    "prmnt_sample= pd.read_excel(\"prominent-sample-users.ods\", engine=\"odf\")\n",
    "display(prmnt_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on_status, Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?max_id=1308843833350909952&id=Mike_Pence (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D006F86708>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "failed on_status, Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?max_id=1009882448757338111&id=ChuckRobbins (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D00FCBB508>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "failed on_status, Twitter error response: status code = 404\n",
      "failed on_status, Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?max_id=977204939624730623&id=adenatfriedman (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D0126DA3C8>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "failed on_status, Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?max_id=1443345981463007234&id=SenatorShaheen (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001D00F837748>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n"
     ]
    }
   ],
   "source": [
    "## DO NOT RUN THIS CELL AGAIN\n",
    "\n",
    "## Data collection\n",
    "\n",
    "# import packages and insert credentials\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import time\n",
    "\n",
    "access_token = \"1251443436865101826-t9GSG62F8K4bLLVJekcCoo9975YJ90\"\n",
    "access_token_secret = \"udDISsUmw1uE6i5xaGQCilZiXtdMCpau8wO1ktgmoUO7g\"\n",
    "consumer_key = \"r4oNYdWLj6lMWVFh61yW4h5vP\"\n",
    "consumer_secret = \"b6OBU1dsmUrEcPpGUJllrlcy3a54C7JlW2r0mZscDSTn5XLdQX\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "# scrape 3200 Tweets per user (tweepy limitation)\n",
    "user_names = prmnt_sample['User_name'].tolist()\n",
    "count = 3200\n",
    "\n",
    "column_names = ['Author']\n",
    "tweets_prmnt_sample = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for user in user_names:\n",
    "    try:     \n",
    "        tweets = tweepy.Cursor(api.user_timeline,id=user).items(count)\n",
    "        tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
    "        tweets_prmnt_indv = pd.DataFrame(tweets_list)\n",
    "        tweets_prmnt_indv['Author'] = user\n",
    "        \n",
    "        frames = [tweets_prmnt_sample, tweets_prmnt_indv]\n",
    "        tweets_prmnt_sample = pd.concat(frames)\n",
    "\n",
    "    \n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2021-10-13 12:53:24</td>\n",
       "      <td>1.448271e+18</td>\n",
       "      <td>Bill, Audrey, Chris, Glen — you’re about to sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2021-10-12 14:44:40</td>\n",
       "      <td>1.447936e+18</td>\n",
       "      <td>RT @blueorigin: “We are just at the beginning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2021-10-11 14:03:45</td>\n",
       "      <td>1.447564e+18</td>\n",
       "      <td>I’m game. https://t.co/JVbuGzztje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2021-10-11 03:28:58</td>\n",
       "      <td>1.447404e+18</td>\n",
       "      <td>Listen and be open, but don’t let anybody tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2021-10-07 15:56:07</td>\n",
       "      <td>1.446142e+18</td>\n",
       "      <td>Anderson laughs through the whole interview. \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>greta</td>\n",
       "      <td>2021-07-09 02:09:52</td>\n",
       "      <td>1.413319e+18</td>\n",
       "      <td>Free legal advice: when hiring a lawyer, in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>greta</td>\n",
       "      <td>2021-07-09 02:08:48</td>\n",
       "      <td>1.413319e+18</td>\n",
       "      <td>Free legal advice: if you have a legal problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>greta</td>\n",
       "      <td>2021-07-09 02:01:34</td>\n",
       "      <td>1.413317e+18</td>\n",
       "      <td>Free legal advice: if you are embroiled in a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>greta</td>\n",
       "      <td>2021-07-09 02:00:24</td>\n",
       "      <td>1.413317e+18</td>\n",
       "      <td>Free legal advice: beware of the lawyer who is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>greta</td>\n",
       "      <td>2021-07-09 01:59:35</td>\n",
       "      <td>1.413317e+18</td>\n",
       "      <td>free legal advice: beware of any lawyer who te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Author                   0             1  \\\n",
       "0     JeffBezos 2021-10-13 12:53:24  1.448271e+18   \n",
       "1     JeffBezos 2021-10-12 14:44:40  1.447936e+18   \n",
       "2     JeffBezos 2021-10-11 14:03:45  1.447564e+18   \n",
       "3     JeffBezos 2021-10-11 03:28:58  1.447404e+18   \n",
       "4     JeffBezos 2021-10-07 15:56:07  1.446142e+18   \n",
       "...         ...                 ...           ...   \n",
       "3195     greta  2021-07-09 02:09:52  1.413319e+18   \n",
       "3196     greta  2021-07-09 02:08:48  1.413319e+18   \n",
       "3197     greta  2021-07-09 02:01:34  1.413317e+18   \n",
       "3198     greta  2021-07-09 02:00:24  1.413317e+18   \n",
       "3199     greta  2021-07-09 01:59:35  1.413317e+18   \n",
       "\n",
       "                                                      2  \n",
       "0     Bill, Audrey, Chris, Glen — you’re about to sh...  \n",
       "1     RT @blueorigin: “We are just at the beginning,...  \n",
       "2                     I’m game. https://t.co/JVbuGzztje  \n",
       "3     Listen and be open, but don’t let anybody tell...  \n",
       "4     Anderson laughs through the whole interview. \\...  \n",
       "...                                                 ...  \n",
       "3195  Free legal advice: when hiring a lawyer, in a ...  \n",
       "3196  Free legal advice: if you have a legal problem...  \n",
       "3197  Free legal advice: if you are embroiled in a d...  \n",
       "3198  Free legal advice: beware of the lawyer who is...  \n",
       "3199  free legal advice: beware of any lawyer who te...  \n",
       "\n",
       "[528900 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## DO NOT RUN AGAIN\n",
    "display(tweets_prmnt_sample)\n",
    "\n",
    "# save dataframe as csv file (so that the collection process does not have to be repeated)\n",
    "#tweets_prmnt_sample.to_csv(r'C:\\Users\\Monique\\Documents\\UVT\\Master Data Science\\THESIS\\Data and coding\\prominent-sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "process_prmnt_sample = pd.read_csv('prominent-sample.csv')\n",
    "\n",
    "# rename the columns\n",
    "process_prmnt_sample = process_prmnt_sample.set_axis(['User_name', 'Date', 'Tweet_ID', 'Text'], axis=1, inplace=False)\n",
    "\n",
    "# delete columns with dates and tweet id \n",
    "process_prmnt_sample = process_prmnt_sample.drop('Date', 1)\n",
    "process_prmnt_sample = process_prmnt_sample.drop('Tweet_ID', 1)\n",
    "\n",
    "# remove retweets\n",
    "process_prmnt_sample = process_prmnt_sample[~process_prmnt_sample.Text.str.startswith('RT')]\n",
    "\n",
    "# exclude users with less than 100 original tweets\n",
    "process_prmnt_sample = process_prmnt_sample.groupby('User_name').filter(lambda x : len(x)>99)\n",
    "\n",
    "# concatenate sample of 100 Tweets per user\n",
    "process_prmnt_sample = process_prmnt_sample.groupby('User_name').head(100).reset_index(drop=True)\n",
    "process_prmnt_sample = process_prmnt_sample.groupby(['User_name'], as_index = False).agg({'Text': list})\n",
    "\n",
    "# attach binary gender label to dataframe (i.e. concatinate original and scraped dataframe)\n",
    "process_prmnt_sample = pd.merge(process_prmnt_sample, prmnt_sample, on='User_name', how='left')\n",
    "\n",
    "# reset the index\n",
    "process_prmnt_sample.reset_index(inplace=True)\n",
    "process_prmnt_sample = process_prmnt_sample.drop(['index'], axis=1)\n",
    "\n",
    "# lowercasing\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    process_prmnt_sample['Text'][index] = ''.join(process_prmnt_sample['Text'][index]).lower()\n",
    "    \n",
    "# replace all URLs with 'URL'\n",
    "import re\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    process_prmnt_sample['Text'][index] = re.sub(r'http\\S+', 'URL', ''.join(process_prmnt_sample['Text'][index]))\n",
    "\n",
    "# replace all usernames with 'USER'\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    process_prmnt_sample['Text'][index] = re.sub(r'\\B@\\w+', 'USER', ''.join(process_prmnt_sample['Text'][index]))\n",
    "\n",
    "# create an additional tokenized text column (word tokenization)\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "process_prmnt_sample['tokenized_text'] = np.nan\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    process_prmnt_sample['tokenized_text'][index] = word_tokenize(process_prmnt_sample['Text'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_name</th>\n",
       "      <th>Text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Gender_label</th>\n",
       "      <th>Gender_binary</th>\n",
       "      <th>Succession</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_char</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>avg_tweet_len</th>\n",
       "      <th>divers</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>PoS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOC</td>\n",
       "      <td>badass 👏🏽👏🏽👏🏽 URL have a strong dem party, we ...</td>\n",
       "      <td>Alexandria Ocasio-Cortez</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>American politician, activist and economist. S...</td>\n",
       "      <td>[badass, 👏🏽👏🏽👏🏽, URL, have, a, strong, dem, pa...</td>\n",
       "      <td>1978</td>\n",
       "      <td>9399</td>\n",
       "      <td>4.751769</td>\n",
       "      <td>19.78</td>\n",
       "      <td>0.410516</td>\n",
       "      <td>0.126121</td>\n",
       "      <td>0.468022</td>\n",
       "      <td>[(badass, NN), (👏🏽👏🏽👏🏽, NN), (URL, NNP), (have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlbertBourla</td>\n",
       "      <td>it’s always particularly gratifying when our s...</td>\n",
       "      <td>Albert Bourla</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>Greek veterinarian and the chairman and chief ...</td>\n",
       "      <td>[it, ’, s, always, particularly, gratifying, w...</td>\n",
       "      <td>2049</td>\n",
       "      <td>10746</td>\n",
       "      <td>5.244510</td>\n",
       "      <td>20.49</td>\n",
       "      <td>0.349927</td>\n",
       "      <td>0.233540</td>\n",
       "      <td>0.544612</td>\n",
       "      <td>[(it, PRP), (’, VBZ), (s, JJ), (always, RB), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlexSalmond</td>\n",
       "      <td>how was that for a fight back - that’s the way...</td>\n",
       "      <td>Alex Salmond</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>Scottish politician who served as First Minist...</td>\n",
       "      <td>[how, was, that, for, a, fight, back, -, that,...</td>\n",
       "      <td>1902</td>\n",
       "      <td>9955</td>\n",
       "      <td>5.233964</td>\n",
       "      <td>19.02</td>\n",
       "      <td>0.383807</td>\n",
       "      <td>0.342672</td>\n",
       "      <td>0.564946</td>\n",
       "      <td>[(how, WRB), (was, VBD), (that, IN), (for, IN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmbaniTina</td>\n",
       "      <td>shakti: for courage and conviction, for good t...</td>\n",
       "      <td>Tina Ambani</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Indian actress and chairperson of the Mumbai-b...</td>\n",
       "      <td>[shakti, :, for, courage, and, conviction, ,, ...</td>\n",
       "      <td>2326</td>\n",
       "      <td>11267</td>\n",
       "      <td>4.843938</td>\n",
       "      <td>23.26</td>\n",
       "      <td>0.360275</td>\n",
       "      <td>0.372404</td>\n",
       "      <td>0.610172</td>\n",
       "      <td>[(shakti, NN), (:, :), (for, IN), (courage, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AnnCurry</td>\n",
       "      <td>USER whoa.wishing quiet moments of peace for e...</td>\n",
       "      <td>Ann Curry</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>American journalist and photojournalist, Co-an...</td>\n",
       "      <td>[USER, whoa.wishing, quiet, moments, of, peace...</td>\n",
       "      <td>1573</td>\n",
       "      <td>7529</td>\n",
       "      <td>4.786395</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.393516</td>\n",
       "      <td>0.189374</td>\n",
       "      <td>0.543503</td>\n",
       "      <td>[(USER, NNP), (whoa.wishing, VBG), (quiet, JJ)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>travisk</td>\n",
       "      <td>computation powered by light! excited to be a ...</td>\n",
       "      <td>Travis Kalanick</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>American businessman best known as the co-foun...</td>\n",
       "      <td>[computation, powered, by, light, !, excited, ...</td>\n",
       "      <td>1484</td>\n",
       "      <td>7288</td>\n",
       "      <td>4.911051</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.425876</td>\n",
       "      <td>0.261477</td>\n",
       "      <td>0.553851</td>\n",
       "      <td>[(computation, NN), (powered, VBN), (by, IN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>trussliz</td>\n",
       "      <td>our flag flies as a symbol of openness, freedo...</td>\n",
       "      <td>Liz Truss</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>British politician serving as Foreign Secretar...</td>\n",
       "      <td>[our, flag, flies, as, a, symbol, of, openness...</td>\n",
       "      <td>1967</td>\n",
       "      <td>10535</td>\n",
       "      <td>5.355872</td>\n",
       "      <td>19.67</td>\n",
       "      <td>0.345704</td>\n",
       "      <td>0.274609</td>\n",
       "      <td>0.487636</td>\n",
       "      <td>[(our, PRP$), (flag, NN), (flies, NNS), (as, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>vestager</td>\n",
       "      <td>all member states have signed up for the treat...</td>\n",
       "      <td>Margrethe Vestager</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Danish politician and European Commissioner in...</td>\n",
       "      <td>[all, member, states, have, signed, up, for, t...</td>\n",
       "      <td>1927</td>\n",
       "      <td>9425</td>\n",
       "      <td>4.891022</td>\n",
       "      <td>19.27</td>\n",
       "      <td>0.401661</td>\n",
       "      <td>0.308455</td>\n",
       "      <td>0.492737</td>\n",
       "      <td>[(all, DT), (member, NN), (states, NNS), (have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>vonderleyen</td>\n",
       "      <td>très heureuse d’avoir rencontré USER pour la p...</td>\n",
       "      <td>Ursula von der Leyen</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>German politician and physician who has been P...</td>\n",
       "      <td>[très, heureuse, d, ’, avoir, rencontré, USER,...</td>\n",
       "      <td>2109</td>\n",
       "      <td>11490</td>\n",
       "      <td>5.448080</td>\n",
       "      <td>21.09</td>\n",
       "      <td>0.429587</td>\n",
       "      <td>0.185418</td>\n",
       "      <td>0.442426</td>\n",
       "      <td>[(très, NN), (heureuse, NN), (d, NN), (’, NNP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>wendykopp</td>\n",
       "      <td>such a heartfelt reflection and story – thanks...</td>\n",
       "      <td>Wendy Kopp</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>American entrepreneur, CEO and co-founder of T...</td>\n",
       "      <td>[such, a, heartfelt, reflection, and, story, –...</td>\n",
       "      <td>1481</td>\n",
       "      <td>7796</td>\n",
       "      <td>5.264011</td>\n",
       "      <td>14.81</td>\n",
       "      <td>0.342336</td>\n",
       "      <td>0.366423</td>\n",
       "      <td>0.532342</td>\n",
       "      <td>[(such, JJ), (a, DT), (heartfelt, JJ), (reflec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_name                                               Text  \\\n",
       "0             AOC  badass 👏🏽👏🏽👏🏽 URL have a strong dem party, we ...   \n",
       "1    AlbertBourla  it’s always particularly gratifying when our s...   \n",
       "2     AlexSalmond  how was that for a fight back - that’s the way...   \n",
       "3      AmbaniTina  shakti: for courage and conviction, for good t...   \n",
       "4        AnnCurry  USER whoa.wishing quiet moments of peace for e...   \n",
       "..            ...                                                ...   \n",
       "225       travisk  computation powered by light! excited to be a ...   \n",
       "226      trussliz  our flag flies as a symbol of openness, freedo...   \n",
       "227      vestager  all member states have signed up for the treat...   \n",
       "228   vonderleyen  très heureuse d’avoir rencontré USER pour la p...   \n",
       "229     wendykopp  such a heartfelt reflection and story – thanks...   \n",
       "\n",
       "                       Author Gender_label  Gender_binary  \\\n",
       "0    Alexandria Ocasio-Cortez       female              1   \n",
       "1              Albert Bourla          male              0   \n",
       "2                Alex Salmond         male              0   \n",
       "3                Tina Ambani        female              1   \n",
       "4                  Ann Curry        female              1   \n",
       "..                        ...          ...            ...   \n",
       "225          Travis Kalanick          male              0   \n",
       "226                 Liz Truss       female              1   \n",
       "227        Margrethe Vestager       female              1   \n",
       "228      Ursula von der Leyen       female              1   \n",
       "229                Wendy Kopp       female              1   \n",
       "\n",
       "                                            Succession  \\\n",
       "0    American politician, activist and economist. S...   \n",
       "1    Greek veterinarian and the chairman and chief ...   \n",
       "2    Scottish politician who served as First Minist...   \n",
       "3    Indian actress and chairperson of the Mumbai-b...   \n",
       "4    American journalist and photojournalist, Co-an...   \n",
       "..                                                 ...   \n",
       "225  American businessman best known as the co-foun...   \n",
       "226  British politician serving as Foreign Secretar...   \n",
       "227  Danish politician and European Commissioner in...   \n",
       "228  German politician and physician who has been P...   \n",
       "229  American entrepreneur, CEO and co-founder of T...   \n",
       "\n",
       "                                        tokenized_text  n_words  n_char  \\\n",
       "0    [badass, 👏🏽👏🏽👏🏽, URL, have, a, strong, dem, pa...     1978    9399   \n",
       "1    [it, ’, s, always, particularly, gratifying, w...     2049   10746   \n",
       "2    [how, was, that, for, a, fight, back, -, that,...     1902    9955   \n",
       "3    [shakti, :, for, courage, and, conviction, ,, ...     2326   11267   \n",
       "4    [USER, whoa.wishing, quiet, moments, of, peace...     1573    7529   \n",
       "..                                                 ...      ...     ...   \n",
       "225  [computation, powered, by, light, !, excited, ...     1484    7288   \n",
       "226  [our, flag, flies, as, a, symbol, of, openness...     1967   10535   \n",
       "227  [all, member, states, have, signed, up, for, t...     1927    9425   \n",
       "228  [très, heureuse, d, ’, avoir, rencontré, USER,...     2109   11490   \n",
       "229  [such, a, heartfelt, reflection, and, story, –...     1481    7796   \n",
       "\n",
       "      avg_len  avg_tweet_len    divers  polarity  subjectivity  \\\n",
       "0    4.751769          19.78  0.410516  0.126121      0.468022   \n",
       "1    5.244510          20.49  0.349927  0.233540      0.544612   \n",
       "2    5.233964          19.02  0.383807  0.342672      0.564946   \n",
       "3    4.843938          23.26  0.360275  0.372404      0.610172   \n",
       "4    4.786395          15.73  0.393516  0.189374      0.543503   \n",
       "..        ...            ...       ...       ...           ...   \n",
       "225  4.911051          14.84  0.425876  0.261477      0.553851   \n",
       "226  5.355872          19.67  0.345704  0.274609      0.487636   \n",
       "227  4.891022          19.27  0.401661  0.308455      0.492737   \n",
       "228  5.448080          21.09  0.429587  0.185418      0.442426   \n",
       "229  5.264011          14.81  0.342336  0.366423      0.532342   \n",
       "\n",
       "                                                   PoS  \n",
       "0    [(badass, NN), (👏🏽👏🏽👏🏽, NN), (URL, NNP), (have...  \n",
       "1    [(it, PRP), (’, VBZ), (s, JJ), (always, RB), (...  \n",
       "2    [(how, WRB), (was, VBD), (that, IN), (for, IN)...  \n",
       "3    [(shakti, NN), (:, :), (for, IN), (courage, NN...  \n",
       "4    [(USER, NNP), (whoa.wishing, VBG), (quiet, JJ)...  \n",
       "..                                                 ...  \n",
       "225  [(computation, NN), (powered, VBN), (by, IN), ...  \n",
       "226  [(our, PRP$), (flag, NN), (flies, NNS), (as, I...  \n",
       "227  [(all, DT), (member, NN), (states, NNS), (have...  \n",
       "228  [(très, NN), (heureuse, NN), (d, NN), (’, NNP)...  \n",
       "229  [(such, JJ), (a, DT), (heartfelt, JJ), (reflec...  \n",
       "\n",
       "[230 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of words\n",
    "process_prmnt_sample['n_words'] = process_prmnt_sample['tokenized_text'].str.len()\n",
    "\n",
    "# number of characters\n",
    "process_prmnt_sample['n_char'] = process_prmnt_sample['Text'].str.len()\n",
    "\n",
    "# average lenght of words (n_char divided by n_words)\n",
    "process_prmnt_sample['avg_len'] = process_prmnt_sample['n_char']/process_prmnt_sample['n_words']\n",
    "\n",
    "# average number of words per tweet\n",
    "process_prmnt_sample['avg_tweet_len'] = process_prmnt_sample['n_words']/100\n",
    "\n",
    "# vocabulary diversity (number of tokens divided by number of types) higher is more divers\n",
    "process_prmnt_sample['divers'] = np.nan\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    process_prmnt_sample['divers'][index] = len(set(process_prmnt_sample['tokenized_text'][index])) / process_prmnt_sample['n_words'][index]\n",
    "\n",
    "# overall polarity\n",
    "from textblob import TextBlob\n",
    "process_prmnt_sample['polarity'] = np.nan\n",
    "\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    text_blob = TextBlob(process_prmnt_sample['Text'][index])\n",
    "    process_prmnt_sample['polarity'][index] = text_blob.sentiment.polarity\n",
    "    \n",
    "# overall subjectivity\n",
    "process_prmnt_sample['subjectivity'] = np.nan\n",
    "\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    text_blob = TextBlob(process_prmnt_sample['Text'][index])\n",
    "    process_prmnt_sample['subjectivity'][index] = text_blob.sentiment.subjectivity\n",
    "\n",
    "# PoS-tagging\n",
    "import nltk\n",
    "process_prmnt_sample['PoS'] = np.nan\n",
    "\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    process_prmnt_sample['PoS'][index] = nltk.pos_tag(process_prmnt_sample['tokenized_text'][index])\n",
    "    \n",
    "display(process_prmnt_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word uni-grams\n",
    "uni_gram = pd.read_csv('word_uni_grams.csv')\n",
    "uni_gram = uni_gram['0'].tolist()\n",
    "\n",
    "for word in uni_gram:\n",
    "    process_prmnt_sample[word] = 0 \n",
    "\n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    for word in process_prmnt_sample['tokenized_text'][index]:\n",
    "        if word in uni_gram:\n",
    "            process_prmnt_sample[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character tri-grams\n",
    "tri_gram = pd.read_csv('character_tri_grams.csv')\n",
    "tri_gram = tri_gram['0'].tolist()\n",
    "\n",
    "for ngram in tri_gram:\n",
    "    process_prmnt_sample[ngram] = 0 \n",
    "\n",
    "for index in range(0, len(process_prmnt_sample)): \n",
    "    tri_gram_index = [process_prmnt_sample['Text'][index][i:i+3] for i in range(len(process_prmnt_sample['Text'][index])-1)]\n",
    "    \n",
    "    for ngram in tri_gram_index:\n",
    "        if ngram in tri_gram:\n",
    "            process_prmnt_sample[ngram][index] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the raw frequency of PoS tags\n",
    "from collections import Counter\n",
    "pos_total = pd.read_csv('pos_total_set.csv')\n",
    "pos_total = pos_total['0'].tolist()\n",
    "\n",
    "for pos in pos_total[:15]:\n",
    "    process_prmnt_sample[pos] = 0\n",
    "    \n",
    "for index in range(0, len(process_prmnt_sample)):\n",
    "    pos_row = Counter([j for i,j in process_prmnt_sample['PoS'][index]])\n",
    "    \n",
    "    process_prmnt_sample['NN'][index] = pos_row.get('NN') \n",
    "    process_prmnt_sample['JJ'][index] = pos_row.get('JJ')\n",
    "    process_prmnt_sample['NNP'][index] = pos_row.get('NNP')\n",
    "    process_prmnt_sample['IN'][index] = pos_row.get('IN')\n",
    "    process_prmnt_sample['DT'][index] = pos_row.get('DT')\n",
    "    process_prmnt_sample['RB'][index] = pos_row.get('RB')\n",
    "    process_prmnt_sample['.'][index] = pos_row.get('.')\n",
    "    process_prmnt_sample['VB'][index] = pos_row.get('VB')\n",
    "    process_prmnt_sample['NNS'][index] = pos_row.get('NNS')\n",
    "    process_prmnt_sample['PRP'][index] = pos_row.get('PRP')\n",
    "    process_prmnt_sample['VBP'][index] = pos_row.get('VBP')\n",
    "    process_prmnt_sample['VBZ'][index] = pos_row.get('VBZ')\n",
    "    process_prmnt_sample['VBD'][index] = pos_row.get('VBD')\n",
    "    process_prmnt_sample['CC'][index] = pos_row.get('CC')\n",
    "    process_prmnt_sample['TO'][index] = pos_row.get('TO')\n",
    "    \n",
    "process_prmnt_sample['NN'] =  process_prmnt_sample['NN'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['JJ'] =  process_prmnt_sample['JJ'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['NNP'] =  process_prmnt_sample['NNP'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['IN'] =  process_prmnt_sample['IN'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['DT'] =  process_prmnt_sample['DT'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['RB'] =  process_prmnt_sample['RB'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['.'] =  process_prmnt_sample['.'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['VB'] =  process_prmnt_sample['VB'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['NNS'] =  process_prmnt_sample['NNS'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['PRP'] =  process_prmnt_sample['PRP'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['VBP'] =  process_prmnt_sample['VBP'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['VBZ'] =  process_prmnt_sample['VBZ'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['VBD'] =  process_prmnt_sample['VBD'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['CC'] =  process_prmnt_sample['CC'] / process_prmnt_sample['n_words']\n",
    "process_prmnt_sample['TO'] =  process_prmnt_sample['TO'] / process_prmnt_sample['n_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequency \"my\":\n",
      "0    6.937500\n",
      "1    8.881356\n",
      "Name: my , dtype: float64\n",
      "\n",
      "Word frequency \"me\":\n",
      "0    12.758929\n",
      "1    11.838983\n",
      "Name: me , dtype: float64\n",
      "\n",
      "Share of determiners\n",
      "0    0.067246\n",
      "1    0.065449\n",
      "Name: DT, dtype: float64\n",
      "\n",
      "Polarity score\n",
      "0    0.206659\n",
      "1    0.238080\n",
      "Name: polarity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_determiner = process_prmnt_sample.groupby(['Gender_binary'], as_index = False).mean()\n",
    "\n",
    "print('Word frequency \"my\":')\n",
    "print(feature_determiner['my '])\n",
    "print()\n",
    "print('Word frequency \"me\":')\n",
    "print(feature_determiner['me '])\n",
    "print()\n",
    "print('Share of determiners')\n",
    "print(feature_determiner['DT'])\n",
    "print()\n",
    "print('Polarity score')\n",
    "print(feature_determiner['polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of best models on prominent sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prmnt_sample = process_prmnt_sample.drop('PoS', 1)\n",
    "x_prominent = process_prmnt_sample.iloc[:, 7:len(process_prmnt_sample.columns)]\n",
    "x_prominent = x_prominent.fillna(0)\n",
    "y_prominent = process_prmnt_sample['Gender_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('x_train.csv')\n",
    "x_train = x_train.drop('nan', 1)\n",
    "y_train = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5434782608695652\n",
      "[[107   5]\n",
      " [100  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67       112\n",
      "           1       0.78      0.15      0.26       118\n",
      "\n",
      "    accuracy                           0.54       230\n",
      "   macro avg       0.65      0.55      0.46       230\n",
      "weighted avg       0.65      0.54      0.46       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "RF = RandomForestClassifier(criterion = 'gini',\n",
    "                                        n_estimators = 160,\n",
    "                                        max_features = 1000,\n",
    "                                        max_depth = 60,\n",
    "                                        random_state = 0)\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred = RF.predict(x_prominent)\n",
    "\n",
    "print(accuracy_score(y_prominent, y_pred))\n",
    "print(confusion_matrix(y_prominent, y_pred))\n",
    "print(classification_report(y_prominent, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5869565217391305\n",
      "[[109   3]\n",
      " [ 92  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.70       112\n",
      "           1       0.90      0.22      0.35       118\n",
      "\n",
      "    accuracy                           0.59       230\n",
      "   macro avg       0.72      0.60      0.53       230\n",
      "weighted avg       0.72      0.59      0.52       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(max_iter = 100,\n",
    "                        penalty = 'l2')\n",
    "\n",
    "LR.fit(x_train, y_train)\n",
    "y_pred = LR.predict(x_prominent)\n",
    "\n",
    "print(accuracy_score(y_prominent, y_pred))\n",
    "print(confusion_matrix(y_prominent, y_pred))\n",
    "print(classification_report(y_prominent, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6304347826086957\n",
      "[[53 59]\n",
      " [26 92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.47      0.55       112\n",
      "           1       0.61      0.78      0.68       118\n",
      "\n",
      "    accuracy                           0.63       230\n",
      "   macro avg       0.64      0.63      0.62       230\n",
      "weighted avg       0.64      0.63      0.62       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel = 'linear',\n",
    "              C = 0.001,\n",
    "              gamma = 0.05,\n",
    "              random_state = 0) \n",
    "\n",
    "SVM.fit(x_train, y_train)\n",
    "y_pred = SVM.predict(x_prominent)\n",
    "            \n",
    "print(accuracy_score(y_prominent, y_pred))\n",
    "print(confusion_matrix(y_prominent, y_pred))\n",
    "print(classification_report(y_prominent, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
